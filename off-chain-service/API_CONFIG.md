# ğŸš€ LLM API é…ç½®è¯´æ˜

## âœ… å·²å®Œæˆçš„ä¿®æ”¹

### 1. ä» Gemini API åˆ‡æ¢åˆ° OpenAI å…¼å®¹ API

**ä¹‹å‰**ï¼šä½¿ç”¨ Google Gemini APIï¼ˆéœ€è¦ä»£ç†ï¼Œåœ°åŒºå—é™ï¼‰

**ç°åœ¨**ï¼šä½¿ç”¨ OpenAI å…¼å®¹çš„ä¸­è½¬ APIï¼ˆå›½å†…å¯ç›´æ¥è®¿é—®ï¼‰

---

## ğŸ“‹ å½“å‰é…ç½®

### API ä¿¡æ¯

```bash
API Key:   sk-your-api-key
Base URL:  https://api.chatanywhere.tech/v1
Model:     gpt-4o-mini
```

**è¯´æ˜**ï¼š
- `gpt-4o-mini` æ˜¯ OpenAI æœ€æ–°çš„ç»æµå‹æ¨¡å‹
- ä½ æåˆ°çš„ `gpt-4.1-mini` å¯èƒ½æ˜¯æŒ‡è¿™ä¸ªæ¨¡å‹ï¼ˆOpenAI æ²¡æœ‰ 4.1 ç‰ˆæœ¬ï¼‰
- å¦‚æœä½ çš„ API æ”¯æŒå…¶ä»–æ¨¡å‹ï¼Œå¯ä»¥åœ¨ `.env` æ–‡ä»¶ä¸­ä¿®æ”¹ `LLM_MODEL`

### å¯ç”¨æ¨¡å‹åˆ—è¡¨

æ ¹æ®ä½ çš„ä¸­è½¬æœåŠ¡ï¼Œå¯èƒ½æ”¯æŒä»¥ä¸‹æ¨¡å‹ï¼š

| æ¨¡å‹åç§° | è¯´æ˜ | æˆæœ¬ |
|---------|------|------|
| `gpt-4o-mini` | GPT-4o çš„è½»é‡ç‰ˆï¼Œé€Ÿåº¦å¿«ã€æˆæœ¬ä½ | â­â­â­â­â­ æ¨è |
| `gpt-3.5-turbo` | GPT-3.5 ç³»åˆ—ï¼Œæ€§ä»·æ¯”é«˜ | â­â­â­â­ |
| `gpt-4-turbo` | GPT-4 Turboï¼Œèƒ½åŠ›å¼ºä½†æˆæœ¬é«˜ | â­â­â­ |
| `gpt-4o` | GPT-4o å®Œæ•´ç‰ˆï¼Œèƒ½åŠ›æœ€å¼º | â­â­ |

**å¦‚ä½•ä¿®æ”¹æ¨¡å‹**ï¼š

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# æ”¹ä¸ºå…¶ä»–æ¨¡å‹
LLM_MODEL=gpt-3.5-turbo
```

---

## ğŸ”§ ä¿®æ”¹çš„æ–‡ä»¶

### 1. `src/config.ts`

**å˜æ›´**ï¼š
- ç§»é™¤äº† `geminiApiKey` å’Œ `geminiModel`
- æ–°å¢äº† `llmApiKey`ã€`llmBaseUrl`ã€`llmModel`
- æ›´æ–°äº† `rpcUrl` é»˜è®¤å€¼ä¸º `http://127.0.0.1:9545`

```typescript
export const config = {
  // LLM API (OpenAI Compatible)
  llmApiKey: process.env.LLM_API_KEY || "",
  llmBaseUrl: process.env.LLM_BASE_URL || "https://api.openai.com/v1",
  llmModel: process.env.LLM_MODEL || "gpt-4-turbo",
  // ...
};
```

### 2. `src/gemini.ts` â†’ `src/llm.ts`

**å˜æ›´**ï¼š
- é‡å‘½åæ–‡ä»¶ä¸º `llm.ts`
- ä½¿ç”¨ `openai` SDK æ›¿ä»£ `@google/generative-ai`
- é‡å†™äº† API è°ƒç”¨é€»è¾‘ä»¥é€‚é… OpenAI æ ¼å¼

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
import OpenAI from "openai";

export class LLMRiskAnalyzer {
  private client: OpenAI;

  constructor() {
    this.client = new OpenAI({
      apiKey: config.llmApiKey,
      baseURL: config.llmBaseUrl,  // æ”¯æŒè‡ªå®šä¹‰ Base URL
    });
  }

  async analyzeProtocol(protocolDescription: string): Promise<RiskAnalysis> {
    const completion = await this.client.chat.completions.create({
      model: config.llmModel,
      messages: [
        { role: "system", content: "You are a DeFi risk analyst..." },
        { role: "user", content: prompt }
      ],
      temperature: 0.3,
      response_format: { type: "json_object" }  // å¼ºåˆ¶è¿”å› JSON
    });
    
    const text = completion.choices[0]?.message?.content || "";
    return this.parseResponse(text);
  }
}
```

### 3. `src/index.ts`

**å˜æ›´**ï¼š
- å¯¼å…¥ `LLMRiskAnalyzer` æ›¿ä»£ `GeminiRiskAnalyzer`
- æ›´æ–°æ‰€æœ‰ç›¸å…³å¼•ç”¨å’Œæ—¥å¿—è¾“å‡º

```typescript
import { LLMRiskAnalyzer } from "./llm";

class AegisOffChainService {
  private llmAnalyzer: LLMRiskAnalyzer;
  
  constructor() {
    this.llmAnalyzer = new LLMRiskAnalyzer();
  }
}
```

### 4. `.env` æ–‡ä»¶

**å®Œæ•´é…ç½®**ï¼š

```bash
# LLM API Configuration
LLM_API_KEY=sk-your-api-key
LLM_BASE_URL=https://api.chatanywhere.tech/v1
LLM_MODEL=gpt-4o-mini

# Blockchain Configuration
PRIVATE_KEY=0xYourPrivateKey
RPC_URL=http://127.0.0.1:9545
CHAIN_ID=31337
YIELD_RISK_AGENT_ADDRESS=0xA51c1fc2f0D1a1b8494Ed1FE312d7C3a78Ed91C0

# Service Configuration
PORT=3001
LOG_LEVEL=info
```

### 5. `package.json`

**æ–°å¢ä¾èµ–**ï¼š

```json
{
  "dependencies": {
    "openai": "^4.0.0",  // æ–°å¢
    // ... å…¶ä»–ä¾èµ–
  }
}
```

---

## ğŸ§ª æµ‹è¯•ç»“æœ

### å¯åŠ¨æ—¥å¿—

```
============================================================
ğŸ¤– Aegis YieldRiskAgent - Off-Chain Service
============================================================
ğŸ¤– LLM Risk Analyzer initialized
   Base URL: https://api.chatanywhere.tech/v1
   Model: gpt-4o-mini

âœ… Configuration validated

ğŸ§ª Testing LLM API connection...
   Sending test request to LLM API...
âœ… LLM API connection successful!
   Response: OK

ğŸ§ª Testing blockchain connection...
âœ… Blockchain connection successful
   Network: unknown Chain ID: 31337n
   Wallet balance: 9999.989 ETH

ğŸ‘‚ Listening for ServiceRequested events...

============================================================
âœ… Service is running!
============================================================

ğŸŒ API server running on http://localhost:3001
```

**ç»“è®º**ï¼šâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å¯åŠ¨æœåŠ¡

```bash
cd /home/hy/develop/defi-learning/yieldRiskAgent/off-chain-service
npm start
```

### æµ‹è¯• API

**1. æäº¤åè®®æè¿°**

```bash
curl -X POST http://localhost:3001/protocol \
  -H "Content-Type: application/json" \
  -d '{
    "description": "Uniswap V3 æ˜¯ä¸€ä¸ªå»ä¸­å¿ƒåŒ–äº¤æ˜“æ‰€ï¼Œé‡‡ç”¨é›†ä¸­æµåŠ¨æ€§æ¨¡å‹..."
  }'
```

**å“åº”**ï¼š
```json
{
  "hash": "0x1234...",
  "message": "Protocol description saved"
}
```

**2. ä»åŒºå—é“¾è¯·æ±‚é£é™©åˆ†æ**

```bash
cd /home/hy/develop/defi-learning/yieldRiskAgent
npx hardhat run scripts/interact.ts --network localhost
```

**3. è·å–åˆ†ææŠ¥å‘Š**

```bash
curl http://localhost:3001/report/0
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
  "protocolName": "Uniswap V3",
  "overallRiskScore": 35,
  "riskLevel": "Medium",
  "analysisSummary": "Uniswap V3 æ˜¯ä¸€ä¸ªæˆç†Ÿçš„ DEX...",
  "riskVectors": [
    {
      "type": "Economic Risk",
      "detail": "é›†ä¸­æµåŠ¨æ€§å¯èƒ½å¯¼è‡´...",
      "severity": "Medium"
    },
    // ...
  ]
}
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æ›´æ¢æ¨¡å‹ï¼Ÿ

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# æ”¹ä¸ºæ›´ä¾¿å®œçš„æ¨¡å‹
LLM_MODEL=gpt-3.5-turbo

# æˆ–æ›´å¼ºå¤§çš„æ¨¡å‹
LLM_MODEL=gpt-4-turbo
```

é‡å¯æœåŠ¡ç”Ÿæ•ˆã€‚

### Q2: ä¸­è½¬ API è¿”å› 401 é”™è¯¯

**åŸå› **ï¼šAPI Key æ— æ•ˆæˆ–è¿‡æœŸã€‚

**è§£å†³**ï¼š
1. æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ `LLM_API_KEY` æ˜¯å¦æ­£ç¡®
2. è®¿é—® https://api.chatanywhere.tech ç¡®è®¤è´¦æˆ·çŠ¶æ€
3. å¦‚æœéœ€è¦ï¼Œæ›´æ–° API Key

### Q3: ä¸­è½¬ API è¿”å› 429 é”™è¯¯

**åŸå› **ï¼šè¯·æ±‚é¢‘ç‡è¿‡é«˜æˆ–é…é¢ç”¨å°½ã€‚

**è§£å†³**ï¼š
1. æ£€æŸ¥è´¦æˆ·ä½™é¢å’Œé…é¢
2. æ·»åŠ è¯·æ±‚å»¶è¿Ÿæˆ–é‡è¯•é€»è¾‘
3. å‡çº§è´¦æˆ·å¥—é¤

### Q4: å¦‚ä½•ä½¿ç”¨å…¶ä»–ä¸­è½¬æœåŠ¡ï¼Ÿ

å¦‚æœä½ æƒ³ä½¿ç”¨å…¶ä»–ä¸­è½¬æœåŠ¡ï¼ˆå¦‚ OpenAI å®˜æ–¹ã€Azure OpenAI ç­‰ï¼‰ï¼Œåªéœ€ä¿®æ”¹ `.env`ï¼š

```bash
# ä½¿ç”¨ OpenAI å®˜æ–¹ï¼ˆéœ€è¦ä»£ç†ï¼‰
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=sk-your-api-key

# ä½¿ç”¨å…¶ä»–ä¸­è½¬æœåŠ¡
LLM_BASE_URL=https://your-proxy-service.com/v1
LLM_API_KEY=your-api-key
```

### Q5: æ¨¡å‹åç§°å†™é”™äº†æ€ä¹ˆåŠï¼Ÿ

æœåŠ¡å¯åŠ¨æ—¶ä¼šæµ‹è¯•è¿æ¥ï¼Œå¦‚æœæ¨¡å‹åç§°é”™è¯¯ï¼Œä¼šçœ‹åˆ°ç±»ä¼¼é”™è¯¯ï¼š

```
âŒ LLM API connection failed!
   Error: The model `gpt-4.1-mini` does not exist
```

æ£€æŸ¥ä½ çš„ä¸­è½¬æœåŠ¡æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨ï¼Œå¹¶æ›´æ–° `.env` ä¸­çš„ `LLM_MODEL`ã€‚

---

## ğŸ“Š ä¸ Gemini API çš„å¯¹æ¯”

| ç‰¹æ€§ | Gemini API | OpenAI å…¼å®¹ API |
|------|-----------|----------------|
| **åœ°åŒºé™åˆ¶** | âŒ ä¸­å›½å¤§é™†ä¸å¯ç”¨ | âœ… é€šè¿‡ä¸­è½¬å¯ç”¨ |
| **éœ€è¦ä»£ç†** | âœ… æ˜¯ | âŒ å¦ |
| **é…ç½®å¤æ‚åº¦** | ğŸ”´ é«˜ | ğŸŸ¢ ä½ |
| **API ç¨³å®šæ€§** | ğŸŸ¡ è¾ƒæ–°ï¼Œå¯èƒ½æœ‰å˜åŒ– | ğŸŸ¢ æˆç†Ÿç¨³å®š |
| **ç”Ÿæ€ç³»ç»Ÿ** | ğŸŸ¡ è¾ƒæ–° | ğŸŸ¢ éå¸¸æˆç†Ÿ |
| **æˆæœ¬** | ğŸŸ¢ ç›¸å¯¹ä¾¿å®œ | ğŸŸ¡ ä¸­ç­‰ |
| **ä¸­æ–‡æ”¯æŒ** | ğŸŸ¢ ä¼˜ç§€ | ğŸŸ¢ ä¼˜ç§€ |

---

## ğŸ¯ æ€»ç»“

### âœ… ä¼˜ç‚¹

1. **å›½å†…å¯ç”¨**ï¼šæ— éœ€ä»£ç†ï¼Œé€šè¿‡ä¸­è½¬æœåŠ¡ç›´æ¥è®¿é—®
2. **é…ç½®ç®€å•**ï¼šåªéœ€ä¸‰ä¸ªç¯å¢ƒå˜é‡
3. **ç”Ÿæ€æˆç†Ÿ**ï¼šOpenAI SDK ç¨³å®šå¯é 
4. **çµæ´»æ€§é«˜**ï¼šå¯è½»æ¾åˆ‡æ¢ä¸åŒçš„ä¸­è½¬æœåŠ¡æˆ–æ¨¡å‹

### ğŸ“ æ³¨æ„äº‹é¡¹

1. **API Key å®‰å…¨**ï¼šä¸è¦æ³„éœ²ä½ çš„ API Key
2. **æˆæœ¬æ§åˆ¶**ï¼šç›‘æ§ API è°ƒç”¨æ¬¡æ•°å’Œè´¹ç”¨
3. **æ¨¡å‹é€‰æ‹©**ï¼šæ ¹æ®éœ€æ±‚åœ¨æ€§èƒ½å’Œæˆæœ¬é—´å¹³è¡¡

### ğŸ”„ åç»­ä¼˜åŒ–å»ºè®®

1. **æ·»åŠ ç¼“å­˜**ï¼šå¯¹ç›¸åŒåè®®çš„åˆ†æç»“æœè¿›è¡Œç¼“å­˜
2. **é”™è¯¯é‡è¯•**ï¼šæ·»åŠ  API è°ƒç”¨å¤±è´¥çš„é‡è¯•æœºåˆ¶
3. **æµå¼å“åº”**ï¼šä½¿ç”¨ streaming æ¨¡å¼å®æ—¶è¿”å›åˆ†æç»“æœ
4. **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒåŒæ—¶åˆ†æå¤šä¸ªåè®®

---

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹æ—¥å¿—è¾“å‡ºï¼š`npm start` ä¼šæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
2. æ£€æŸ¥ `.env` é…ç½®æ˜¯å¦æ­£ç¡®
3. æµ‹è¯•ä¸­è½¬ API æ˜¯å¦å¯ç”¨ï¼š
   ```bash
  curl https://api.chatanywhere.tech/v1/models \
    -H "Authorization: Bearer sk-your-api-key"
   ```

---

**é…ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥å¯åŠ¨æœåŠ¡å¹¶å¼€å§‹ä½¿ç”¨äº†ï¼** ğŸ‰

